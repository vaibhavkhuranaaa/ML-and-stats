# -*- coding: utf-8 -*-
"""PA4 (1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SDnbZZBAlZkl8L_ePOtx9YLVped7SnR2
"""

from sklearn.datasets import load_svmlight_file
from scipy.sparse import csr_matrix
import matplotlib.pyplot as plt
import pandas as pd
import numpy as nm
import collections
import csv
import re

from google.colab import files
uploaded = files.upload()

"""#Loading Train and Test data"""

# Load training data
X_train_data, y_train_data = load_svmlight_file("articles.train")

# Load test data
X_test_data, y_test_data= load_svmlight_file("articles.test")

# Load word mapping
words = pd.read_csv("words.map.txt", header=None, names=["Word"])

# Checking the number of features (columns/words) and number of articles (rows) in each dataset
no_features = X_train_data.shape[1]
no_train_articles = X_train_data.shape[0]
no_test_articles = X_test_data.shape[0]

print("Number of features:", no_features)
print("Number of articles in training data:", no_train_articles)
print("Number of articles in test data:", no_test_articles)
print("Number of unique words:", len(words))

"""#Resizing train and test data"""

X_train_data.resize((X_train_data.shape[0], words.shape[0]))
X_test_data.resize((X_test_data.shape[0], words.shape[0]))

# confirming the no. of columns in all three datasets after resizing
print(words.shape)
print(X_train_data.shape)
print(X_test_data.shape)

from sklearn.svm import SVC
import numpy as np

def new_label_y(arr, true_class):
        new_arr = np.where(arr == true_class, 1, -1)
        return new_arr

def train_SVM(x_data, y_data, true_class, C=None, kernel='linear'):
  y_new = new_label_y(y_data, true_class)
  if C is None:
        model = SVC(kernel=kernel, C=1e10)
  else:
        model = SVC(kernel=kernel, C=C)
  model.fit(x_data, y_new)
  return model

"""#Class 1 vs all other hard margin classifiers"""

from sklearn.metrics import accuracy_score, confusion_matrix

# Train SVM classifier
SVM1 = train_SVM(X_train_data, y_train_data, true_class=1.0, C=None)

# Predict on test data
y_test_pred = SVM1.predict(X_test_data)

# Change labels for evaluation
ytest_new = new_label_y(y_test_data, true_class=1.0)

# Calculate accuracy
accuracy = accuracy_score(ytest_new, y_test_pred)
print("Accuracy:", accuracy)

# Calculate confusion matrix
confusion_mat = confusion_matrix(ytest_new, y_test_pred)
print("Confusion Matrix:")
print(confusion_mat)

# Print predicted labels
print("Predicted Labels:")
print(y_test_pred)

"""#Class 2 vs all other hard margin classifiers"""

from sklearn.metrics import accuracy_score, confusion_matrix

# Train SVM classifier
SVM1 = train_SVM(X_train_data, y_train_data, true_class=2.0, C=None)

# Predict on test data
y_test_pred = SVM1.predict(X_test_data)

# Change labels for evaluation
ytest_new = new_label_y(y_test_data, true_class=2.0)

# Calculate accuracy
accuracy = accuracy_score(ytest_new, y_test_pred)
print("Accuracy:", accuracy)

# Calculate confusion matrix
confusion_mat = confusion_matrix(ytest_new, y_test_pred)
print("Confusion Matrix:")
print(confusion_mat)

# Print predicted labels
print("Predicted Labels:")
print(y_test_pred)

"""#Class 3 vs all other hard margin classifiers"""

from sklearn.metrics import accuracy_score, confusion_matrix

# Train SVM classifier
SVM1 = train_SVM(X_train_data, y_train_data, true_class=3.0, C=None)

# Predict on test data
y_test_pred = SVM1.predict(X_test_data)

# Change labels for evaluation
ytest_new = new_label_y(y_test_data, true_class=3.0)

# Calculate accuracy
accuracy = accuracy_score(ytest_new, y_test_pred)
print("Accuracy:", accuracy)

# Calculate confusion matrix
confusion_mat = confusion_matrix(ytest_new, y_test_pred)
print("Confusion Matrix:")
print(confusion_mat)

# Print predicted labels
print("Predicted Labels:")
print(y_test_pred)

"""#Class 4 vs all other hard margin classifiers"""

from sklearn.metrics import accuracy_score, confusion_matrix

# Train SVM classifier
SVM1 = train_SVM(X_train_data, y_train_data, true_class=4.0, C=None)

# Predict on test data
y_test_pred = SVM1.predict(X_test_data)

# Change labels for evaluation
ytest_new = new_label_y(y_test_data, true_class=4.0)

# Calculate accuracy
accuracy = accuracy_score(ytest_new, y_test_pred)
print("Accuracy:", accuracy)

# Calculate confusion matrix
confusion_mat = confusion_matrix(ytest_new, y_test_pred)
print("Confusion Matrix:")
print(confusion_mat)

# Print predicted labels
print("Predicted Labels:")
print(y_test_pred)

"""#One VS Rest Classifier"""

from sklearn.multiclass import OneVsRestClassifier
from sklearn.svm import LinearSVC
from sklearn.metrics import accuracy_score, confusion_matrix

# Fit One-vs-Rest classifier
ovr1 = OneVsRestClassifier(LinearSVC(random_state=0, C=1e10), n_jobs=4)
ovr1.fit(X_train_data, y_train_data)

# Predict on test data
y_test_pred = ovr1.predict(X_test_data)

# Calculate accuracy
accuracy = accuracy_score(y_test_data, y_test_pred)
print("Accuracy:", accuracy)

# Calculate confusion matrix
confusion_mat = confusion_matrix(y_test_data, y_test_pred)
print("Confusion Matrix:")
print(confusion_mat)

# Print predicted labels
print("Predicted Labels:")
print(y_test_pred)

"""#c."""

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# Splitting the training data into train (75%) and validation (25%) sets
X_train_p, X_val, y_train_p, y_val = train_test_split(X_train_data, y_train_data, test_size=0.25)

# Array (-3, -2, -1,....,10) for C values which are (2^-3, 2^-2,....,2^10)
pwr = np.arange(-3, 11)

# Initialize arrays to store misclassification errors
err1 = []
err2 = []
err3 = []
err4 = []
cumerr = []
trainerr1 = []
trainerr2 = []
trainerr3 = []
trainerr4 = []

for i in pwr:
    C = 2.0 ** i

    # Training SVM models for each binary classifier
    SVM_SM1 = train_SVM(X_train_p, y_train_p, true_class=1.0, C=C)
    error1 = 1 - accuracy_score(new_label_y(y_val, true_class=1.0), SVM_SM1.predict(X_val))
    err1.append(error1)
    trainerr1.append(1 - SVM_SM1.score(X_train_p, new_label_y(y_train_p, true_class=1.0)))

    SVM_SM2 = train_SVM(X_train_p, y_train_p, true_class=2.0, C=C)
    error2 = 1 - accuracy_score(new_label_y(y_val, true_class=2.0), SVM_SM2.predict(X_val))
    err2.append(error2)
    trainerr2.append(1 - SVM_SM2.score(X_train_p, new_label_y(y_train_p, true_class=2.0)))

    SVM_SM3 = train_SVM(X_train_p, y_train_p, true_class=3.0, C=C)
    error3 = 1 - accuracy_score(new_label_y(y_val, true_class=3.0), SVM_SM3.predict(X_val))
    err3.append(error3)
    trainerr3.append(1 - SVM_SM3.score(X_train_p, new_label_y(y_train_p, true_class=3.0)))

    SVM_SM4 = train_SVM(X_train_p, y_train_p, true_class=4.0, C=C)
    error4 = 1 - accuracy_score(new_label_y(y_val, true_class=4.0), SVM_SM4.predict(X_val))
    err4.append(error4)
    trainerr4.append(1 - SVM_SM4.score(X_train_p, new_label_y(y_train_p, true_class=4.0)))

    # Calculate overall average misclassification error
    cumerr.append((error1 + error2 + error3 + error4) / 4)
    print("Overall misclassification error for C =", C, ":", (error1 + error2 + error3 + error4) / 4)

"""#Plotting missclassification errors"""

import matplotlib.pyplot as plt

fig, errplots = plt.subplots()
errplots.plot(pwr, err1, label='tst error classifier 1')      # Test error from the first binary classifier
errplots.plot(pwr, err2, label='tst error classifier 2')      # Test error from the second binary classifier
errplots.plot(pwr, err3, label='tst error classifier 3')      # Test error from the third binary classifier
errplots.plot(pwr, err4, label='tst error classifier 4')      # Test error from the fourth binary classifier
errplots.plot(pwr, trainerr1, label='trn error classifier 1') # Training error from the first binary classifier
errplots.plot(pwr, trainerr2, label='trn error classifier 2') # Training error from the second binary classifier
errplots.plot(pwr, trainerr3, label='trn error classifier 3') # Training error from the third binary classifier
errplots.plot(pwr, trainerr4, label='trn error classifier 4') # Training error from the fourth binary classifier
errplots.plot(pwr, cumerr, label='overall avg error')         # Average of all 4 classifiers
errplots.set_ylabel('Validation error')
errplots.set_xlabel('Log2(C)')
errplots.legend()
errplots.set_title('Validation error vs. Log2(C)')
plt.show()

"""#d.Comparing accuracies of binary classifier 2 (probably mean 1) vs others"""

from sklearn.metrics import accuracy_score, confusion_matrix

# Training soft margin classifier for class 1 vs classes 2,3,4 with C=0.125
SVM_SM_D1 = train_SVM(X_train_data, y_train_data, true_class=1.0, C=0.125)

# Predicting labels for the test set
y_test_pred = SVM_SM_D1.predict(X_test_data)

# Calculating accuracy score and confusion matrix
ytest_new = new_label_y(y_test_data, true_class=1.0)
accuracy = accuracy_score(ytest_new, y_test_pred)
confusion_mat = confusion_matrix(ytest_new, y_test_pred)

print("Accuracy:", accuracy)
print("Confusion Matrix:")
print(confusion_mat)
print("Predicted Labels:", y_test_pred)

"""#Comparing accuracies of binary classifier 2 vs others"""

from sklearn.metrics import accuracy_score, confusion_matrix

# Training soft margin classifier for class 1 vs classes 2,3,4 with C=0.125
SVM_SM_D1 = train_SVM(X_train_data, y_train_data, true_class=2.0, C=0.125)

# Predicting labels for the test set
y_test_pred = SVM_SM_D1.predict(X_test_data)

# Calculating accuracy score and confusion matrix
ytest_new = new_label_y(y_test_data, true_class=2.0)
accuracy = accuracy_score(ytest_new, y_test_pred)
confusion_mat = confusion_matrix(ytest_new, y_test_pred)

print("Accuracy:", accuracy)
print("Confusion Matrix:")
print(confusion_mat)
print("Predicted Labels:", y_test_pred)

"""#Comparing accuracies of binary classifier 3 vs others"""

from sklearn.metrics import accuracy_score, confusion_matrix

# Training soft margin classifier for class 1 vs classes 2,3,4 with C=0.125
SVM_SM_D1 = train_SVM(X_train_data, y_train_data, true_class=3.0, C=0.125)

# Predicting labels for the test set
y_test_pred = SVM_SM_D1.predict(X_test_data)

# Calculating accuracy score and confusion matrix
ytest_new = new_label_y(y_test_data, true_class=3.0)
accuracy = accuracy_score(ytest_new, y_test_pred)
confusion_mat = confusion_matrix(ytest_new, y_test_pred)

print("Accuracy:", accuracy)
print("Confusion Matrix:")
print(confusion_mat)
print("Predicted Labels:", y_test_pred)

"""#Comparing accuracies of binary classifier 4 vs others"""

from sklearn.metrics import accuracy_score, confusion_matrix

# Training soft margin classifier for class 1 vs classes 2,3,4 with C=0.125
SVM_SM_D1 = train_SVM(X_train_data, y_train_data, true_class=4.0, C=0.125)

# Predicting labels for the test set
y_test_pred = SVM_SM_D1.predict(X_test_data)

# Calculating accuracy score and confusion matrix
ytest_new = new_label_y(y_test_data, true_class=4.0)
accuracy = accuracy_score(ytest_new, y_test_pred)
confusion_mat = confusion_matrix(ytest_new, y_test_pred)

print("Accuracy:", accuracy)
print("Confusion Matrix:")
print(confusion_mat)
print("Predicted Labels:", y_test_pred)

"""#e."""

from sklearn.preprocessing import normalize

# Normalizing feature vectors
X_train_norm = normalize(X_train_data, norm='l2', axis=1, copy=True, return_norm=False)
X_test_norm = normalize(X_test_data, norm='l2', axis=1, copy=True, return_norm=False)

from sklearn.metrics import accuracy_score, confusion_matrix

# Training soft margin classifier for class 1 vs classes 2,3,4 with C=0.125 with normalized feature vectors
SVM_norm1 = train_SVM(X_train_norm, y_train_data, true_class=1.0, C=0.125)

# Predicting labels for the test set with normalized feature vectors
y_test_pred = SVM_norm1.predict(X_test_norm)

# Calculating accuracy score and confusion matrix
ytest_new = new_label_y(y_test_data, true_class=1.0)
accuracy = accuracy_score(ytest_new, y_test_pred)
confusion_mat = confusion_matrix(ytest_new, y_test_pred)

print("Accuracy:", accuracy)
print("Confusion Matrix:")
print(confusion_mat)
print("Predicted Labels:", y_test_pred)

from sklearn.metrics import accuracy_score, confusion_matrix

# Training soft margin classifier for class 1 vs classes 2,3,4 with C=0.125 with normalized feature vectors
SVM_norm1 = train_SVM(X_train_norm, y_train_data, true_class=2.0, C=0.125)

# Predicting labels for the test set with normalized feature vectors
y_test_pred = SVM_norm1.predict(X_test_norm)

# Calculating accuracy score and confusion matrix
ytest_new = new_label_y(y_test_data, true_class=2.0)
accuracy = accuracy_score(ytest_new, y_test_pred)
confusion_mat = confusion_matrix(ytest_new, y_test_pred)

print("Accuracy:", accuracy)
print("Confusion Matrix:")
print(confusion_mat)
print("Predicted Labels:", y_test_pred)

from sklearn.metrics import accuracy_score, confusion_matrix

# Training soft margin classifier for class 1 vs classes 2,3,4 with C=0.125 with normalized feature vectors
SVM_norm1 = train_SVM(X_train_norm, y_train_data, true_class=3.0, C=0.125)

# Predicting labels for the test set with normalized feature vectors
y_test_pred = SVM_norm1.predict(X_test_norm)

# Calculating accuracy score and confusion matrix
ytest_new = new_label_y(y_test_data, true_class=3.0)
accuracy = accuracy_score(ytest_new, y_test_pred)
confusion_mat = confusion_matrix(ytest_new, y_test_pred)

print("Accuracy:", accuracy)
print("Confusion Matrix:")
print(confusion_mat)
print("Predicted Labels:", y_test_pred)

from sklearn.metrics import accuracy_score, confusion_matrix

# Training soft margin classifier for class 1 vs classes 2,3,4 with C=0.125 with normalized feature vectors
SVM_norm1 = train_SVM(X_train_norm, y_train_data, true_class=4.0, C=0.125)

# Predicting labels for the test set with normalized feature vectors
y_test_pred = SVM_norm1.predict(X_test_norm)

# Calculating accuracy score and confusion matrix
ytest_new = new_label_y(y_test_data, true_class=4.0)
accuracy = accuracy_score(ytest_new, y_test_pred)
confusion_mat = confusion_matrix(ytest_new, y_test_pred)

print("Accuracy:", accuracy)
print("Confusion Matrix:")
print(confusion_mat)
print("Predicted Labels:", y_test_pred)

from sklearn.multiclass import OneVsRestClassifier
from sklearn.svm import LinearSVC
from sklearn.metrics import accuracy_score, confusion_matrix

# Training a multiclass classifier using One-vs-Rest strategy with normalized feature vectors
ovr1 = OneVsRestClassifier(LinearSVC(random_state=0, C=0.125))
modelovr1 = ovr1.fit(X_train_norm, y_train_data)

# Predicting labels for the test set
y_test_pred = modelovr1.predict(X_test_norm)

# Calculating accuracy score and confusion matrix
accuracy = accuracy_score(y_test_data, y_test_pred)
confusion_mat = confusion_matrix(y_test_data, y_test_pred)

print("Accuracy:", accuracy)
print("Confusion Matrix:")
print(confusion_mat)
print("Predicted Labels:", y_test_pred)

"""#f."""

from sklearn.multiclass import OneVsOneClassifier
from sklearn.svm import LinearSVC
from sklearn.metrics import accuracy_score, confusion_matrix

# Training a multiclass classifier using One-vs-One strategy with normalized feature vectors
ovo1 = OneVsOneClassifier(LinearSVC(random_state=0, C=0.125))
modelovo1 = ovo1.fit(X_train_norm, y_train_data)

# Predicting labels for the test set
y_test_pred = modelovo1.predict(X_test_norm)

# Calculating accuracy score and confusion matrix
accuracy = accuracy_score(y_test_data, y_test_pred)
confusion_mat = confusion_matrix(y_test_data, y_test_pred)

print("Accuracy:", accuracy)
print("Confusion Matrix:")
print(confusion_mat)
print("Predicted Labels:", y_test_pred)