{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IDS575_Programming_Assignment_1_Minal Daniel Josh.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWDHgt87ELsC"
      },
      "source": [
        "# **IDS575: Machine Learning and Statistical Methods**\n",
        "## Programming Assignment 1 \n",
        "## April 7, 2021\n",
        "Submitted by:\n",
        "1.   Minal Patil (UIN: 661688111)\n",
        "2.   Daniel Simon (UIN: 676315463)\n",
        "3.   Josh Wilks (UIN: 659102804)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Euea9lSUXC-F",
        "outputId": "eb3811cd-a6b5-4a76-a5fe-cd56eda99c4c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') \n",
        "\n",
        "import os\n",
        "os.chdir('/content/drive/MyDrive/Spring 21/IDS 575 Machine Learning and Statistical Methods for Business Analytics/Programming homework')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMlHnEOxEvBz"
      },
      "source": [
        "## **PART A**: Importing libraries and loading the training and test data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJJPQo0hD0lP",
        "outputId": "21d22153-382b-479e-a430-1987c88434df"
      },
      "source": [
        "from sklearn.datasets import load_svmlight_file\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.sparse import csr_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "X_train, y_train = load_svmlight_file(\"articles.train\")\n",
        "X_test, y_test = load_svmlight_file(\"articles.test\")\n",
        "words = pd.read_csv(\"words.map.txt\")\n",
        "\n",
        "# checking the no. of features (columns/words) and no. of articles (rows) in each dataset\n",
        "print(words.shape)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(61187, 1)\n",
            "(4000, 51949)\n",
            "(2400, 60636)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_YffbYIwEMG"
      },
      "source": [
        "### Resizing the training and test data to match the no. of features (words)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecLZ5x4jvbBf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68e9e525-d642-4e01-e4b8-0da00f68fdf2"
      },
      "source": [
        "X_train.resize((X_train.shape[0], words.shape[0]))\n",
        "X_test.resize((X_test.shape[0], words.shape[0]))\n",
        "\n",
        "# confirming the no. of columns in all three datasets after resizing\n",
        "print(words.shape)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(61187, 1)\n",
            "(4000, 61187)\n",
            "(2400, 61187)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzM3l88Lietn"
      },
      "source": [
        "## **PART** **B** \n",
        "### We performed the following tasks in this part:\n",
        "\n",
        "1. Define a *train_SVM* function to perform 1-vs-all SVM hard-margin classification\n",
        "2. We trained four hard margin classifiers separately for each class to perform 1-vs-all classification. The function *change_ylabels* assigns +1 to our class of interest and -1 to the remaining three classes (for example, if the model classifies class 1 vs classes 3,4,5, *change_ylabels* function would assign labels 1 to 1 and labels 3,4,5 to -1)\n",
        "3. Alternatively, we also used in-built function *OneVsRestClassifier* to perform 1-vs-all classification. This is equivalent to combining results from the four different classifiers learned above"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nLZoHPkfhkz"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# function to change the labels for the class which is classified vs other classes in 1-vs-all\n",
        "# for ex. class 1 vs classes 3,4,5 --> class 1 label would be 1, rest will be -1\n",
        "def change_ylabels(arr, true_class):\n",
        "  new_arr = np.where(arr==true_class,1,-1)\n",
        "  return new_arr\n",
        "\n",
        "# training SVM\n",
        "# C = 1e10 is for hard margin classifier\n",
        "# C value for soft-margin classifiers will be entered manually as we proceed in the assignment\n",
        "\n",
        "def train_SVM(xdata, ydata, true_class, C, kernel='linear'):\n",
        "  y_new = change_ylabels(ydata, true_class)\n",
        "  if C is None:\n",
        "    model = SVC(kernel = kernel, C = 1e10)\n",
        "  else:\n",
        "    model = SVC(kernel = kernel, C = C)\n",
        "  model.fit(xdata, y_new)\n",
        "  return model\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2K3ME3T3_MX4"
      },
      "source": [
        "### 1-vs-all SVM hard-margin classifier: **Class 1-vs-2,3,4**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qP1VBFPNiYV8",
        "outputId": "d9654c4b-3015-444c-c803-710fb8aaf7f3"
      },
      "source": [
        "SVM1 = train_SVM(X_train, y_train, true_class = 1.0, C=None)\n",
        "\n",
        "y_test_pred = SVM1.predict(X_test)\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix \n",
        "ytest_new = change_ylabels(y_test, true_class=1.0)\n",
        "print(accuracy_score(ytest_new, y_test_pred))\n",
        "print(confusion_matrix(ytest_new, y_test_pred))\n",
        "print(y_test_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9579166666666666\n",
            "[[1783   17]\n",
            " [  84  516]]\n",
            "[ 1  1  1 ... -1 -1 -1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l685cqHnSTtV"
      },
      "source": [
        "### 1-vs-all SVM hard-margin classifier: **Class 2-vs-1,3,4**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfurPJ4d06Uf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dfb93a5-5892-437c-c49a-0902234d7853"
      },
      "source": [
        "SVM2 = train_SVM(X_train, y_train, true_class = 2.0, C=None)\n",
        "\n",
        "y_test_pred = SVM2.predict(X_test)\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix \n",
        "ytest_new = change_ylabels(y_test, true_class=2.0)\n",
        "print(accuracy_score(ytest_new, y_test_pred))\n",
        "print(confusion_matrix(ytest_new, y_test_pred))\n",
        "print(y_test_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9341666666666667\n",
            "[[1741   59]\n",
            " [  99  501]]\n",
            "[-1 -1 -1 ... -1 -1 -1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0n68MKrf90kP"
      },
      "source": [
        "### 1-vs-all SVM hard-margin classifier: **Class 3-vs-1,2,4**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CsLc-20SSvU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a7a951c-afa6-49ae-dec0-6b35af527932"
      },
      "source": [
        "SVM3 = train_SVM(X_train, y_train, true_class = 3.0, C=None)\n",
        "\n",
        "y_test_pred = SVM3.predict(X_test)\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix \n",
        "ytest_new = change_ylabels(y_test, true_class=3.0)\n",
        "print(accuracy_score(ytest_new, y_test_pred))\n",
        "print(confusion_matrix(ytest_new, y_test_pred))\n",
        "print(y_test_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9491666666666667\n",
            "[[1754   46]\n",
            " [  76  524]]\n",
            "[-1 -1 -1 ... -1 -1 -1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfwrbherBBbF"
      },
      "source": [
        "### 1-vs-all SVM hard-margin classifier: **Class 4-vs-1,2,3**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAri3fJWA7ty",
        "outputId": "b5f6619b-0d5f-4969-a4e9-1ef4ec868cc1"
      },
      "source": [
        "SVM4 = train_SVM(X_train, y_train, true_class = 4.0, C=None)\n",
        "\n",
        "y_test_pred = SVM4.predict(X_test)\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix \n",
        "ytest_new = change_ylabels(y_test, true_class=4.0)\n",
        "print(accuracy_score(ytest_new, y_test_pred))\n",
        "print(confusion_matrix(ytest_new, y_test_pred))\n",
        "print(y_test_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9408333333333333\n",
            "[[1746   54]\n",
            " [  88  512]]\n",
            "[-1 -1 -1 ...  1  1  1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6x4eO0KovK-0"
      },
      "source": [
        "### 1-vs-all SVM hard-margin classifier using **OneVsRestClassifier**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kE8QtKRNu5zs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e71b6405-7cb1-4cad-b5a2-866195da8675"
      },
      "source": [
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "ovr1 = OneVsRestClassifier((LinearSVC(random_state=0, C=1e10)).fit(X_train, y_train), n_jobs=4)\n",
        "\n",
        "modelovr1 = ovr1.fit(X_train, y_train)\n",
        "y_test_pred = modelovr1.predict(X_test)\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix \n",
        "print(accuracy_score(y_test, y_test_pred))\n",
        "print(confusion_matrix(y_test, y_test_pred))\n",
        "print(y_test_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.90375\n",
            "[[536  27  10  27]\n",
            " [ 17 539  17  27]\n",
            " [  9  24 549  18]\n",
            " [ 10  24  21 545]]\n",
            "[1. 1. 1. ... 4. 4. 4.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RT3aLV8DH8z8"
      },
      "source": [
        "### Test accuracies of all binary classifiers are as below:\n",
        "\n",
        "* SVM1 = 95.8% accuracy on the test data\n",
        "* SVM2 = 93.4% accuracy on the test data\n",
        "* SVM3 = 94.9% accuracy on the test data\n",
        "* SVM4 = 94.1% accuracy on the test data\n",
        "* Test accuracy of OneVsRestClassifier is 90.4%\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3F5kRtMZERy0"
      },
      "source": [
        "## **PART** **C** \n",
        "### We performed the following tasks in this part:\n",
        "\n",
        "1. Split the training data randomly into 75% for training and 25% for validation\n",
        "2. We use different values of C from {0.125, 0.25, 0.5, 1, 2, 4, 8, 16, 32, 64, 128, 256, 512}, and train all four binary classifiers from part b (SVM1, SVM2, SVM3, SVM4) on the 75% training data\n",
        "3. Measure the overall classification error of all four binary classifiers on the 25% validation data, and picked the C which resulted in the lowest validation error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zme7Gc25A5g7",
        "outputId": "baf6ebcc-6ba4-49e0-a6cf-3d51e5b01b33"
      },
      "source": [
        "# Splitting the training data into train (75%) and validation (25%) sets\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train_c, X_val, y_train_c, y_val = train_test_split(X_train, y_train, test_size=0.25)\n",
        "\n",
        "# array (-3, -2, -1,....,10) for C values which are (2^-3, 2^-2,....,2^10)\n",
        "pwr = np.arange(-3,10,1)\n",
        "\n",
        "# for each C value, training all four classifiers on the 75% training data and calculating the validation error on\n",
        "# 25% validation data to pick the best C\n",
        "\n",
        "err1 = []     # array to store misclassification error on the test data from the first binary classifier\n",
        "err2 = []     # array to store misclassification error on the test data from the second binary classifier\n",
        "err3 = []     # array to store misclassification error on the test data from the third binary classifier\n",
        "err4 = []     # array to store misclassification error on the test data from the fourth binary classifier\n",
        "cumerr = []   # array to store the overall average misclassification error on the test data from all four binary classifiers\n",
        "trainerr1 = [] # array to store misclassification error on the training data from the first binary classifier\n",
        "trainerr2 = [] # array to store misclassification error on the training data from the second binary classifier\n",
        "trainerr3 = [] # array to store misclassification error on the training data from the third binary classifier\n",
        "trainerr4 = [] # array to store misclassification error on the training data from the fourth binary classifier\n",
        "for i in pwr:\n",
        "  C = 2.0**i\n",
        "\n",
        "  SVM_SM1 = train_SVM(X_train_c, y_train_c, true_class=1.0, C=C)\n",
        "  error1 = 1 - accuracy_score(change_ylabels(y_val, true_class=1.0), SVM_SM1.predict(X_val))\n",
        "  err1.append(error1)\n",
        "  trainerr1.append(1-SVM_SM1.score(X_train_c, change_ylabels(y_train_c, true_class=1.0)))\n",
        "\n",
        "  SVM_SM2 = train_SVM(X_train_c, y_train_c, true_class=2.0, C=C)\n",
        "  error2 = 1 - accuracy_score(change_ylabels(y_val, true_class=2.0), SVM_SM2.predict(X_val))\n",
        "  err2.append(error2)\n",
        "  trainerr2.append(1-SVM_SM2.score(X_train_c, change_ylabels(y_train_c, true_class=2.0)))\n",
        "\n",
        "  SVM_SM3 = train_SVM(X_train_c, y_train_c, true_class=3.0, C=C)\n",
        "  error3 = 1 - accuracy_score(change_ylabels(y_val, true_class=3.0), SVM_SM3.predict(X_val))\n",
        "  err3.append(error3)\n",
        "  trainerr3.append(1-SVM_SM3.score(X_train_c, change_ylabels(y_train_c, true_class=3.0)))\n",
        "\n",
        "  SVM_SM4 = train_SVM(X_train_c, y_train_c, true_class=4.0, C=C)\n",
        "  error4 = 1 - accuracy_score(change_ylabels(y_val, true_class=4.0), SVM_SM4.predict(X_val))\n",
        "  err4.append(error4)\n",
        "  trainerr4.append(1-SVM_SM4.score(X_train_c, change_ylabels(y_train_c, true_class=4.0)))\n",
        "  cumerr.append((error1+error2+error3+error4)/4)\n",
        "  print(\"Overall misclassification_error for\", C, \"=\", (error1+error2+error3+error4)/4) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overall misclassification_error for 0.125 = 0.039750000000000035\n",
            "Overall misclassification_error for 0.25 = 0.04200000000000004\n",
            "Overall misclassification_error for 0.5 = 0.04350000000000004\n",
            "Overall misclassification_error for 1.0 = 0.04300000000000004\n",
            "Overall misclassification_error for 2.0 = 0.04400000000000004\n",
            "Overall misclassification_error for 4.0 = 0.04400000000000004\n",
            "Overall misclassification_error for 8.0 = 0.04400000000000004\n",
            "Overall misclassification_error for 16.0 = 0.04400000000000004\n",
            "Overall misclassification_error for 32.0 = 0.04400000000000004\n",
            "Overall misclassification_error for 64.0 = 0.04400000000000004\n",
            "Overall misclassification_error for 128.0 = 0.04400000000000004\n",
            "Overall misclassification_error for 256.0 = 0.04400000000000004\n",
            "Overall misclassification_error for 512.0 = 0.04400000000000004\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCLLjCSxUo96"
      },
      "source": [
        "### Plotting missclassification errors against Log2(C) to see how the error vary with different values of C\n",
        "\n",
        "*   We observed that **C = 0.125** gives the lowest average misclassification error of 3.5% on the test data (this maybe different each time we run the code because we are randomly splitting the training data into 75:25 ratio)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "-Zoj38CvUUc_",
        "outputId": "4ee2ff7c-f4a0-446a-c1ee-cb0c7e1fae48"
      },
      "source": [
        "# plotting missclassification errors of all four binary classifiers and the overall classification error on one plot\n",
        "fig, errplots = plt.subplots()\n",
        "errplots.plot(pwr,err1, label='tst error classifier 1')      #test error from first binary classifier\n",
        "errplots.plot(pwr,err2, label='tst error classifier 2')      #test error from second binary classifier\n",
        "errplots.plot(pwr,err3, label='tst error classifier 3')      #test error from third binary classifier\n",
        "errplots.plot(pwr,err4, label='tst error classifier 4')      #test error from fourth binary classifier\n",
        "errplots.plot(pwr,trainerr1, label='trn error classifier 1') #training error from first binary classifier\n",
        "errplots.plot(pwr,trainerr2, label='trn error classifier 2') #training error from second binary classifier\n",
        "errplots.plot(pwr,trainerr3, label='trn error classifier 3') #training error from third binary classifier\n",
        "errplots.plot(pwr,trainerr4, label='trn error classifier 4') #training error from fourth binary classifier\n",
        "errplots.plot(pwr,cumerr, label='overall avg error')      #avg of all 4 classifiers\n",
        "errplots.set_ylabel('validation error')\n",
        "errplots.set_xlabel('Log2(C)')\n",
        "errplots.legend()\n",
        "errplots.set_title('Validation error vs. Log2(C)')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Validation error vs. Log2(C)')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEyUGxZGNQCl"
      },
      "source": [
        "## **PART** **D** \n",
        "### We performed the following tasks in this part:\n",
        "\n",
        "1. We used the best C value as 0.125 picked from the part C and trained four soft margin classifiers with this C on the entire training data X_train and y_train (In part B, we trained hard margin classifiers using our function train_SVM with C = 1e10. In this part, we will be using the same function train_SVM with C = 0.125 for soft margin classifiers).\n",
        "2. We compare the accuracies of these four soft-margin classifiers to those of hard-margin classifiers in part B"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsPCghAiF_OL",
        "outputId": "ece43575-a518-4293-f763-345c1d01c643"
      },
      "source": [
        "## training soft margin classifier for class 1 vs classes 2,3,4 with C=0.125\n",
        "## Class 1\n",
        "SVM_SM_D1 = train_SVM(X_train, y_train, true_class = 1.0, C=0.125)\n",
        "\n",
        "y_test_pred = SVM_SM_D1.predict(X_test)\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix \n",
        "ytest_new = change_ylabels(y_test, true_class=1.0)\n",
        "print(accuracy_score(ytest_new, y_test_pred))\n",
        "print(confusion_matrix(ytest_new, y_test_pred))\n",
        "print(y_test_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9616666666666667\n",
            "[[1789   11]\n",
            " [  81  519]]\n",
            "[ 1  1  1 ... -1 -1 -1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BT3H1E_gaJO_"
      },
      "source": [
        "### Comparing accuracies of binary classifier for class 1 vs. class 2,3,4\n",
        "\n",
        "*   Hard margin classifier in part B    = 95.8%\n",
        "*   Soft margin classifier with C 0.125 = 96.2%\n",
        "\n",
        "Soft margin is observed to perform better in this case\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0I--JQ2KOVwH",
        "outputId": "f00f1d35-60c8-4ddf-9d26-ccea25e49d29"
      },
      "source": [
        "## training soft margin classifier for class 2 vs classes 1,3,4 with C=0.125\n",
        "## Class 2\n",
        "SVM_SM_D2 = train_SVM(X_train, y_train, true_class = 2.0, C=0.125)\n",
        "\n",
        "y_test_pred = SVM_SM_D2.predict(X_test)\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix \n",
        "ytest_new = change_ylabels(y_test, true_class=2.0)\n",
        "print(accuracy_score(ytest_new, y_test_pred))\n",
        "print(confusion_matrix(ytest_new, y_test_pred))\n",
        "print(y_test_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.94625\n",
            "[[1760   40]\n",
            " [  89  511]]\n",
            "[-1 -1 -1 ... -1 -1 -1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nRYX449a536"
      },
      "source": [
        "### Comparing accuracies of binary classifier for class 2 vs. class 1,3,4\n",
        "\n",
        "*   Hard margin classifier in part B    = 93.4%\n",
        "*   Soft margin classifier with C 0.125 = 94.6%\n",
        "\n",
        "Soft margin is observed to perform better in this case"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYIhIz6HOp6G",
        "outputId": "426f313f-a3ac-43c4-adc3-571eb9173d3b"
      },
      "source": [
        "## training soft margin classifier for class 3 vs classes 1,2,4 with C=0.125\n",
        "## Class 3\n",
        "SVM_SM_D3 = train_SVM(X_train, y_train, true_class = 3.0, C=0.125)\n",
        "\n",
        "y_test_pred = SVM_SM_D3.predict(X_test)\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix \n",
        "ytest_new = change_ylabels(y_test, true_class=3.0)\n",
        "print(accuracy_score(ytest_new, y_test_pred))\n",
        "print(confusion_matrix(ytest_new, y_test_pred))\n",
        "print(y_test_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9654166666666667\n",
            "[[1782   18]\n",
            " [  65  535]]\n",
            "[-1 -1 -1 ... -1 -1 -1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwoNTTIWbI_u"
      },
      "source": [
        "### Comparing accuracies of binary classifier for class 3 vs. class 1,2,4\n",
        "\n",
        "*   Hard margin classifier in part B    = 94.9%\n",
        "*   Soft margin classifier with C 0.125 = 96.5%\n",
        "\n",
        "Soft margin is observed to perform better in this case"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qc1a_zksO2vx",
        "outputId": "a2ed62db-783b-4f4f-de08-5d975de06bb0"
      },
      "source": [
        "## training soft margin classifier for class 4 vs classes 1,2,3 with C=0.125\n",
        "## Class 4\n",
        "SVM_SM_D4 = train_SVM(X_train, y_train, true_class = 4.0, C=0.125)\n",
        "\n",
        "y_test_pred = SVM_SM_D4.predict(X_test)\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix \n",
        "ytest_new = change_ylabels(y_test, true_class=4.0)\n",
        "print(accuracy_score(ytest_new, y_test_pred))\n",
        "print(confusion_matrix(ytest_new, y_test_pred))\n",
        "print(y_test_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9416666666666667\n",
            "[[1749   51]\n",
            " [  89  511]]\n",
            "[-1 -1 -1 ...  1  1  1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "427wuy9cbe-r"
      },
      "source": [
        "### Comparing accuracies of binary classifier for class 4 vs. class 1,2,3\n",
        "\n",
        "*   Hard margin classifier in part B    = 94.1%\n",
        "*   Soft margin classifier with C 0.125 = 94.2%\n",
        "\n",
        "Although the difference in accuracies is not significant in this case, soft margin still has higher accuracy than that of hard margin classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sicELehxfvs",
        "outputId": "a2362222-7f4f-4cba-eab4-99164bc57619"
      },
      "source": [
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "ovr1 = OneVsRestClassifier((LinearSVC(random_state=0, C=0.125)).fit(X_train, y_train), n_jobs=4)\n",
        "\n",
        "modelovr1 = ovr1.fit(X_train, y_train)\n",
        "y_test_pred = modelovr1.predict(X_test)\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix \n",
        "print(accuracy_score(y_test, y_test_pred))\n",
        "print(confusion_matrix(y_test, y_test_pred)) #confusion matrix with all 4 classes, all the off-diagonal values are misclassifications\n",
        "print(y_test_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9233333333333333\n",
            "[[546  17  12  25]\n",
            " [ 13 554  10  23]\n",
            " [  6  19 561  14]\n",
            " [ 11  21  13 555]]\n",
            "[1. 1. 1. ... 4. 4. 4.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuY_I4VVzO6l"
      },
      "source": [
        "### Comparing accuracies of multiclass classifier OneVsRestClassifier\n",
        "\n",
        "*   Multiclass hard margin classifier in part B = 90.4%\n",
        "*   Multiclass soft margin classifier with C 0.125 = 92.3%\n",
        "\n",
        "Soft margin multiclass classifier has higher accuracy than that of hard margin multiclass classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoLjvp4dPwFe"
      },
      "source": [
        "### We observed that in our case, soft margin classifiers work better than hard margin classifiers\n",
        "Soft margin and hard margin classifiers work differently on different dataset. If the data is linearly separable, then hard-margin classifiers work better allowing no misclassifications, but if the data is not completely linearly separable, soft margin and hard margin may work differently.\n",
        "\n",
        "In our case, soft margin classifiers work better, the reason behind this could be that our data is not completely linearly separable with a few data points closer to the classifying hyperplane, the model missclassifies more examples with hard margin, and gives less error with soft margin by classifying examples closer to the hyperplane correctly. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3GeOaOVrKcr"
      },
      "source": [
        "## **PART** **E** \n",
        "### We performed the following tasks in this part:\n",
        "\n",
        "1. We normalized our feature vectors X_train and X_test by dividing each feature with the L2 norm of the feature vector. Our normalized feature vectors are X_train_norm and X_test_norm, which we will be using in this part.\n",
        "2. We compare the accuracies of these four soft-margin classifiers with normalized feature vectors to those of soft margin classifiers without normalized vectors in part D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wi8P_LK6rOAG"
      },
      "source": [
        "# normalizing feature vectors\n",
        "from sklearn.preprocessing import normalize\n",
        "X_train_norm = normalize(X_train, norm='l2', axis=1, copy=True, return_norm=False)\n",
        "X_test_norm = normalize(X_test, norm='l2', axis=1, copy=True, return_norm=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fb6MyQKrtjgq",
        "outputId": "557361eb-2559-49f1-9b3d-0b9ee7c4a31f"
      },
      "source": [
        "## training soft margin classifier for class 1 vs classes 2,3,4 with C=0.125 with normalized feature vectors\n",
        "## Class 1\n",
        "\n",
        "SVM_norm1 = train_SVM(X_train_norm, y_train, true_class = 1.0, C=0.125)\n",
        "\n",
        "y_test_pred = SVM_norm1.predict(X_test_norm)\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix \n",
        "ytest_new = change_ylabels(y_test, true_class=1.0)\n",
        "print(accuracy_score(ytest_new, y_test_pred))\n",
        "print(confusion_matrix(ytest_new, y_test_pred))\n",
        "print(y_test_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9216666666666666\n",
            "[[1795    5]\n",
            " [ 183  417]]\n",
            "[ 1 -1 -1 ... -1 -1 -1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBdCakdrvW70"
      },
      "source": [
        "### Comparing accuracies of soft margin binary classifier for class 1 vs. class 2,3,4\n",
        "\n",
        "*   Without normalized feature vectors in part D    = 96.2%\n",
        "*   With normalized feature vectors as seen above = 92.2%\n",
        "\n",
        "We observe that soft margin classifiers with normalized feature vectors result in less accuracy or more classification error as compared to soft margin classifiers without normalized feature vectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ghGEUMZuvsn",
        "outputId": "83cabcaf-bd00-4cce-96ad-3d04db23efae"
      },
      "source": [
        "## training soft margin classifier for class 2 vs classes 1,3,4 with C=0.125 with normalized feature vectors\n",
        "## Class 2\n",
        "\n",
        "SVM_norm2 = train_SVM(X_train_norm, y_train, true_class = 2.0, C=0.125)\n",
        "\n",
        "y_test_pred = SVM_norm2.predict(X_test_norm)\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix \n",
        "ytest_new = change_ylabels(y_test, true_class=2.0)\n",
        "print(accuracy_score(ytest_new, y_test_pred))\n",
        "print(confusion_matrix(ytest_new, y_test_pred))\n",
        "print(y_test_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8166666666666667\n",
            "[[1800    0]\n",
            " [ 440  160]]\n",
            "[-1 -1 -1 ... -1 -1 -1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GddeFaTwXkg"
      },
      "source": [
        "### Comparing accuracies of soft margin binary classifier for class 2 vs. class 1,3,4\n",
        "\n",
        "*   Without normalized feature vectors in part D = 94.6%\n",
        "*   With normalized feature vectors as seen above = 81.7%\n",
        "\n",
        "We observe that soft margin classifiers with normalized feature vectors result in less accuracy or more classification error as compared to soft margin classifiers without normalized feature vectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0gojltIvo31",
        "outputId": "2f5074ba-5d2f-461e-fe7b-fbad39de17f7"
      },
      "source": [
        "## training soft margin classifier for class 3 vs classes 1,2,4 with C=0.125 with normalized feature vectors\n",
        "## Class 3\n",
        "\n",
        "SVM_norm3 = train_SVM(X_train_norm, y_train, true_class = 3.0, C=0.125)\n",
        "\n",
        "y_test_pred = SVM_norm3.predict(X_test_norm)\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix \n",
        "ytest_new = change_ylabels(y_test, true_class=3.0)\n",
        "print(accuracy_score(ytest_new, y_test_pred))\n",
        "print(confusion_matrix(ytest_new, y_test_pred))\n",
        "print(y_test_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8991666666666667\n",
            "[[1795    5]\n",
            " [ 237  363]]\n",
            "[-1 -1 -1 ... -1 -1 -1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8SDOhzqwoHR"
      },
      "source": [
        "### Comparing accuracies of soft margin binary classifier for class 3 vs. class 1,2,4\n",
        "\n",
        "*   Without normalized feature vectors in part D = 96.5%\n",
        "*   With normalized feature vectors as seen above = 89.9%\n",
        "\n",
        "We observe that soft margin classifiers with normalized feature vectors result in less accuracy or more classification error as compared to soft margin classifiers without normalized feature vectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtTlYhrbvwPO",
        "outputId": "b2385a90-71df-4786-f8c0-481d38307473"
      },
      "source": [
        "## training soft margin classifier for class 4 vs classes 1,2,3 with C=0.125 with normalized feature vectors\n",
        "## Class 4\n",
        "\n",
        "SVM_norm4 = train_SVM(X_train_norm, y_train, true_class = 4.0, C=0.125)\n",
        "\n",
        "y_test_pred = SVM_norm4.predict(X_test_norm)\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix \n",
        "ytest_new = change_ylabels(y_test, true_class=4.0)\n",
        "print(accuracy_score(ytest_new, y_test_pred))\n",
        "print(confusion_matrix(ytest_new, y_test_pred))\n",
        "print(y_test_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8845833333333334\n",
            "[[1788   12]\n",
            " [ 265  335]]\n",
            "[-1 -1 -1 ...  1  1 -1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBpradJlw7p8"
      },
      "source": [
        "### Comparing accuracies of soft margin binary classifier for class 4 vs. class 1,2,3\n",
        "\n",
        "*   Without normalized feature vectors in part D = 94.2%\n",
        "*   With normalized feature vectors as seen above = 88.5%\n",
        "\n",
        "We observe that soft margin classifiers with normalized feature vectors result in less accuracy or more classification error as compared to soft margin classifiers without normalized feature vectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDsNqBH53CYb",
        "outputId": "f05bc3a6-1383-41fe-8741-4e56b8d67b13"
      },
      "source": [
        "# multiclass classifier OneVsRestClassifier with normalized feature vectors\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "ovr1 = OneVsRestClassifier((LinearSVC(random_state=0, C=0.125)).fit(X_train_norm, y_train), n_jobs=4)\n",
        "\n",
        "modelovr1 = ovr1.fit(X_train_norm, y_train)\n",
        "y_test_pred = modelovr1.predict(X_test_norm)\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix \n",
        "print(accuracy_score(y_test, y_test_pred))\n",
        "print(confusion_matrix(y_test, y_test_pred)) #confusion matrix with all 4 classes, all the off-diagonal values are misclassifications\n",
        "print(y_test_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9116666666666666\n",
            "[[546  12  11  31]\n",
            " [ 26 517  13  44]\n",
            " [ 14   7 565  14]\n",
            " [  8  17  15 560]]\n",
            "[1. 1. 1. ... 4. 4. 4.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-vcxR_a0ZPZ"
      },
      "source": [
        "### Comparing accuracies of soft margin multiclass classifiers \n",
        "\n",
        "*   Without normalized feature vectors in part D = 92.3%\n",
        "*   With normalized feature vectors as seen above = 91.2%\n",
        "\n",
        "We observe that soft margin multiclass classifier with normalized feature vectors result in less accuracy or more classification error as compared to soft margin multiclass classifier without normalized feature vectors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_pvI4z1wPxD"
      },
      "source": [
        "## **PART** **F** \n",
        "### We performed the following tasks in this part:\n",
        "\n",
        "1. Till now, we have trained 1-vs-all classifiers - binary and multiclass. In this part, we train 1-vs-1 classifiers by picking a pair of classes and building a classifier to classify the pair. \n",
        "We used OneVsOneClassier to perform this task. Since we have 4 classes, this classifier trains all (4C2 = 6) binary classifiers to classify every pair of classes. This classifier then picks the class with higher votes.\n",
        "2. We then compare the accuracies of our 1-vs-1 classifier with C=0.125 and normalized feature vectors to that of 1-vs-all classifier with C=0.125 and normalized feature vectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cE9dm2_wTmq",
        "outputId": "08491550-f51f-491e-9c40-31d00e64f271"
      },
      "source": [
        "# one-vs-one classifier with C=0.125 and normalized feature vectors\n",
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "ovo1 = OneVsOneClassifier((LinearSVC(random_state=0, C=0.125)).fit(X_train_norm, y_train), n_jobs=6) #n-job = 6 pairs between 4 classes\n",
        "\n",
        "modelovo1 = ovo1.fit(X_train_norm, y_train)\n",
        "y_test_pred = modelovo1.predict(X_test_norm)\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix \n",
        "print(accuracy_score(y_test, y_test_pred))\n",
        "print(confusion_matrix(y_test, y_test_pred)) #confusion matrix with all 4 classes, all the off-diagonal values are misclassifications\n",
        "print(y_test_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8875\n",
            "[[530  20  13  37]\n",
            " [ 18 519  15  48]\n",
            " [ 21  15 539  25]\n",
            " [ 11  26  21 542]]\n",
            "[1. 1. 1. ... 4. 4. 4.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8DdveuV4FEi"
      },
      "source": [
        "### Comparing accuracies of one-vs-one and one-vs-all multiclass classifiers with C= 0.125 and normalized feature vectors\n",
        "\n",
        "*   One-vs-all multiclass classifier in part E = 91.2%\n",
        "*   One-vs-one multiclass classifier as seen above = 88.8%\n",
        "\n",
        "We observe that one-vs-one multiclass classifier results in less accuracy or more classification error as compared to one-vs-all multiclass classifier (both with C=0.125 and normalized vectors).\n",
        "\n",
        "## 1-vs-all performs better because it is trained on the entire dataset, assigning labels of class of interest as 1 and -1 as other class labels. Whereas, each binary classifier in 1-vs-1 is trained only on the subset of data. (For example, if one binary classifier is built for class pair 1 and 2, the classifier would only be trained on the data of these two classes). Because of this, 1-vs-1 classifier performs poor than the 1-vs-all classifier which is trained using the entire dataset. \n"
      ]
    }
  ]
}